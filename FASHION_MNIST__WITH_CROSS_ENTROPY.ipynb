{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FASHION_MNIST _WITH_CROSS_ENTROPY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY"
      ],
      "metadata": {
        "id": "qzqtw6oYuD7d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "Mn3WwrVvbZEV",
        "outputId": "7dacbda0-5540-45c9-c334-10ad667d988a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 20.85%\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 12.736819852941176\n",
            "Train Accuracy: 26.13%\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 11.896192401960784\n",
            "Train Accuracy: 27.11%\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 11.742023284313726\n",
            "Train Accuracy: 27.35%\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 11.702329656862744\n",
            "Train Accuracy: 27.76%\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 11.63879656862745\n",
            "Train Accuracy: 27.83%\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 11.628299019607843\n",
            "Train Accuracy: 28.02%\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 11.59716911764706\n",
            "Train Accuracy: 28.04%\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 11.595933823529412\n",
            "\n",
            "Total time taken (in seconds): 598.17\n",
            "Test Accuracy: 26.53%\n",
            "Test MSE: 11.8379\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "a=9\n",
        "np.random.seed(a*9755)\n",
        "tf.random.set_seed(a*9755)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_val = X_train[int(0.85*X_train.shape[0]):int(X_train.shape[0])]\n",
        "y_val = y_train[int(0.85*y_train.shape[0]):int(y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train = X_train[0:int(0.85*X_train.shape[0])]\n",
        "y_train = y_train[0:int(0.85*y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "\n",
        "X_val=X_val.reshape(X_val.shape[0],X_val.shape[1]*X_val.shape[2])\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_val=X_val/255.0\n",
        "\n",
        "size_input = X_train.shape[1]\n",
        "size_input_layer = 64\n",
        "size_first_hidden = 32\n",
        "size_second_hidden = 16\n",
        "size_output = 10 #The digits go from 0 to 9 so in total we should have 10 classes\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "\n",
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input,size_input_layer, size_first_hidden, size_second_hidden, size_output, device):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_input_layer, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights for input\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_input_layer]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_input_layer]))\n",
        "     # Initialize weights between input layer and first hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_input_layer, self.size_first_hidden]))\n",
        "    # Initialize biases for first hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "     # Initialize weights between first hidden layer and second hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # Initialize biases for second hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # Initialize weights between second hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    #Compute values in input layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)    \n",
        "    # Compute values in first hidden layer\n",
        "    what = tf.matmul(hhat, self.W2) + self.b2\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute values in second hidden layer\n",
        "    what = tf.matmul(hhat, self.W3) + self.b3\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W4) + self.b4\n",
        "    return tf.nn.softmax(output)\n",
        "\n",
        "  def compute_correct_preds(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "    correct = tf.Variable(0, dtype=tf.float32)\n",
        "    for i in range(y_pred_tf.shape[0]):\n",
        "      if tf.argmax(y_pred_tf[i]) == tf.argmax(y_true_tf[i]):\n",
        "        correct = correct + 1.0\n",
        "    return correct   \n",
        "\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device='none')\n",
        "\n",
        "time_start = time.time()\n",
        "valo_loss = 100.0\n",
        "val_loss  = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "train_loss = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*a*(9755)).batch(20)\n",
        "  correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "\n",
        "  train_loss[0,epoch].assign(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Train Accuracy: {:.2f}%'.format((correct_preds/X_train.shape[0])*100.0))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(4)\n",
        "  valn_loss = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "  for inputs, outputs in val_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    valn_loss = valn_loss + mlp_on_cpu.loss(preds, outputs)\n",
        "  val_loss[0,epoch].assign(np.sum(valn_loss) / X_val.shape[0])\n",
        "  if val_loss[0,epoch] > valo_loss:\n",
        "    break\n",
        "  else:\n",
        "    valo_loss = val_loss[0,epoch]\n",
        "    W1 = mlp_on_cpu.variables[0]\n",
        "    W2 = mlp_on_cpu.variables[1]\n",
        "    W3 = mlp_on_cpu.variables[2]\n",
        "    W4 = mlp_on_cpu.variables[3]\n",
        "    b1 = mlp_on_cpu.variables[4]\n",
        "    b2 = mlp_on_cpu.variables[5]\n",
        "    b3 = mlp_on_cpu.variables[6]\n",
        "    b4 = mlp_on_cpu.variables[7]\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n",
        "\n",
        "train_loss = train_loss[train_loss>0.0]\n",
        "val_loss = val_loss[val_loss>0.0]\n",
        "e = e = tf.range(1, epoch+2, 1)\n",
        "plt.plot(e.numpy(),train_loss.numpy(),e.numpy(),val_loss.numpy())\n",
        "\n",
        "mlp_on_cpu.variables[0].assign(W1)\n",
        "mlp_on_cpu.variables[1].assign(W2)\n",
        "mlp_on_cpu.variables[2].assign(W3)\n",
        "mlp_on_cpu.variables[3].assign(W4)\n",
        "mlp_on_cpu.variables[4].assign(b1)\n",
        "mlp_on_cpu.variables[5].assign(b2)\n",
        "mlp_on_cpu.variables[6].assign(b3)\n",
        "mlp_on_cpu.variables[7].assign(b4)\n",
        "\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "print('Test Accuracy: {:.2f}%'.format((correct_preds/X_test.shape[0])*100.0))\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY AND L1 REGULARIZATION"
      ],
      "metadata": {
        "id": "cppaj0j2xXxK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Rn7KzcwdIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "f0ec4eec-e2e6-4bc0-fe87-7f915f611b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 20.52%\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 12.780595588235293\n",
            "Train Accuracy: 26.56%\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 11.813916666666668\n",
            "\n",
            "Total time taken (in seconds): 168.05\n",
            "Test Accuracy: 26.23%\n",
            "Test MSE: 11.8684\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZf7+8fcnjdCLINI0SJWOBKQnBEtQFHtBQQQVLAhI1rKu3y3urrtrUBBQREQsiAXFglSBJHQIvSO9CwgC0gPP7w/i/pBNSEhmcpKZ+3VdXk7OnGfmPqK3J2fOM4855xARkcAV4nUAERHxLxW9iEiAU9GLiAQ4Fb2ISIBT0YuIBLgwrwNkpGzZsi4qKsrrGCIiBcaiRYv2O+fKZfRcviz6qKgoUlNTvY4hIlJgmNnWzJ7TpRsRkQCXZdGb2Ugz22tmK8/b9pqZrTWz5WY2zsxKZTK2n5mtMrOVZjbGzCJ9GV5ERLKWnTP6UUD8BdumAvWccw2A9cCLFw4ys0rAM0C0c64eEArcn6u0IiJyybIseudcCnDggm1TnHNp6T/OAypnMjwMKGxmYUARYFcusoqISA744hp9d2DihRudczuBRGAbsBs45Jyb4oP3ExGRS5Crojezl4A0YHQGz5UGOgFVgYpAUTN76CKv9biZpZpZ6r59+3ITS0REzpPjojezbkBH4EGX8VdgXg9sds7tc86dBr4CWmb2es654c65aOdcdLlyGd4KKiIiOZCjojezeOA54Dbn3LFMdtsGNDezImZmQHtgTc5iZs/gaT+yeNtBf76FiEiBk53bK8cAc4FaZrbDzHoAQ4DiwFQzW2pmw9L3rWhmEwCcc/OBscBiYEX6ew33z2HAoWOn+Xj+Vu58aw79P1/G3iMn/PVWIiIFiuXHhUeio6NdTmbG/noyjaEzNjBi5iYKhYXSp30NHm4ZRUSY5oWJSGAzs0XOueiMnguoBixWKIzn42szpV8MzaqW4R8T1hA/KIXk9fpwV0SCV0AV/W+qli3KyG5NGdktmrNnHQ+PXMCjH6Sy7efMPk4QEQlcAVn0v4mrXZ7J/dryfHxt5mzcz/VvJJM4eR3HTqVlPVhEJEAEdNEDFAoL5YnYasxIiOWW+hUYMmMD7Qck8+2yXeTHzydERHwt4Iv+N+VLRPLGfY0Y26sFZYpG8MyYJdz3zjxW7zrsdTQREb8KmqL/TXRUGb59ujX/vKM+P+49QsfBM3n565UcPHrK62giIn4RdEUPEBpidL7uSpIS2tG1RRSj52+l3YAkPpq3lTNndTlHRAJLUBb9b0oWCecvt9VlQp821L6iOC9/vZKOg2exYPOBrAeLiBQQQV30v6l9RQnGPNacoZ2v5dCxU9z7zlyeGbOE3YeOex1NRCTXVPTpzIxbGlRgWv9Ynmlfg0mr9hCXmMzQGRs4cfqM1/FERHJMRX+BwhGhPHtDTaY9G0PbmmV5bfI6bhqYwg+rf9LtmCJSIKnoM1GlTBHe6RLNRz2aER4awqMfptLt/YVs3Per19FERC6Jij4LbWqUY2KfNvzplmtYvPUg8QNTeHXCGo6cOO11NBGRbFHRZ0N4aAiPtrma6Qmx3NG4Eu+kbCJuQDJfLtrBWd2OKSL5nIr+EpQrXoj/3N2Qr59qRcVShen/xTLuHjaH5Tt+8TqaiEimVPQ50KhKKcY90ZLX7m7AtgPH6DR0Ni98uZz9v570OpqIyP9Q0edQSIhxT3QVpifE0qNVVcYu2kG7xCTen72Z02fOeh1PROS/VPS5VCIynD91rMOkvm1oVKUUf/1uNbe8OZM5G/Z7HU1EBFDR+0z1y4vzYfdmDO/ShOOnz9B5xHye+HgR2w9osRMR8ZaK3ofMjBvrXsHUfjH0v6EmM9bt5frXkxn4w3rNrhURz6jo/SAyPJTe7WswvX8sN9Qpz8AffqT9gGQmrtit2bUikudU9H5UsVRhhnS+lk8fb07xyDCeGL2Yh96bz/qfjngdTUSCiIo+DzS/+jLG927N3zrVZeXOw3QYNJO/freKQ8c1u1ZE/E9Fn0fCQkPo2iKKGQmx3N+0CqPmbCEuMYlPF2zTYici4lcq+jxWpmgE/7ijPt893ZqryxXlha9WcPvQ2SzaetDraCISoFT0HqlXqSSf92zBoPsbsffICe56ew7Pfr6UvYdPeB1NRAKMit5DZkanRpWY3j+WJ2KrMX7ZbuIGJDM8ZSOn0jS7VkR8Q0WfDxQtFMbz8bWZ3K8t11Utwz8nrCV+YApJ6/Z6HU1EAkCWRW9mI81sr5mtPG/ba2a21syWm9k4MyuVydhSZjY2fd81ZtbCl+EDTdWyRXmvW1Pe79YUB3R7fyGPfpDK1p+Peh1NRAqw7JzRjwLiL9g2FajnnGsArAdezGTsIGCSc6420BBYk8OcQaVd7cuZ3LctL3SozdyN+7nh9RRem7yWoyfTvI4mIgVQlkXvnEsBDlywbYpz7rfWmQdUvnCcmZUE2gLvpY855ZzTF7dnU0RYCL1iqjE9IZaODSowdMZG2g9I5pulOzW7VkQuiS+u0XcHJmawvSqwD3jfzJaY2QgzK+qD9wsq5UtE8vp9jfjyiRaULR5Bn0+Xct8781i967DX0USkgMhV0ZvZS0AaMDqDp8OAa4G3nXONgaPACxd5rcfNLNXMUvft25ebWAGpyVVl+Oap1rx6Z3027PuVjoNn8qevV3Dw6Cmvo4lIPpfjojezbkBH4EGX8bWEHcAO59z89J/Hcq74M+ScG+6ci3bORZcrVy6nsQJaaIjxQLMrmdE/lq4tohizYDuxiUl8NHeLZteKSKZyVPRmFg88B9zmnMvwC9edc3uA7WZWK31Te2B1jlLK75QsEs5fbqvL98+0pk6FErz8zSo6Dp7F/E0/ex1NRPKh7NxeOQaYC9Qysx1m1gMYAhQHpprZUjMblr5vRTObcN7w3sBoM1sONAL+6fMjCGK1ryjBJ49dx1sPXsvh46e5b/g8eo9Zwu5Dx72OJiL5iOXHOziio6Ndamqq1zEKlOOnzjAseSPDkjcSYsbTcdXp0boqkeGhXkcTkTxgZoucc9EZPaeZsQGicEQo/W6oyQ/PxhBTsxyvTV7HjW+kMHX1T7odUyTIqegDTJUyRRjWpQkf97iOiLAQHvswlYffX8iGvb96HU1EPKKiD1Cta5RlYp82vNyxDku2HiR+YAr/nLCGIye02IlIsFHRB7Dw0BB6tK7KjD/Ecte1lXl35ibaJSYzdtEOzup2TJGgoaIPAmWLFeLfdzfg6ydbUbl0YRK+WMZdw+awfIe+kUIkGKjog0jDKqX46omWJN7TkO0HjtNp6GyeH7uc/b+e9DqaiPiRij7IhIQYdzepzIyEGB5rczVfLt5Bu8Qk3pu1mdNntNiJSCBS0Qep4pHh/PHma5jUty2NqpTilfGruXnQTGZv2O91NBHxMRV9kKt+eTE+7N6Md7tGczLtLA+OmE+vjxax/UCG32whIgVQmNcBxHtmxg11ytOmRllGzNzE0BkbmbFuL71iqtErphqFIzS7VqQg0xm9/FdkeChPx9VgWv8Ybqx7BYOm/cj1ryczYcVuza4VKcBU9PI/KpYqzOAHGvPZ480pHhnGk6MX8+CI+azbc8TraCKSAyp6ydR1V1/G+N6teaVTXVbtOszNb87kL9+u4tAxza4VKUhU9HJRYaEhdGkRRVJCLA80q8KHc7fQbkASny7YpsVORAoIFb1kS+miEfz99vp817s11csV44WvVnD70Nks2nrQ62gikgUVvVySuhVL8lnP5gy6vxH7jpzkrrfn8OxnS9l7+ITX0UQkEyp6uWRmRqdGlZjWP4YnY6sxfvlu2iUm8U7yRk6laXatSH6jopccK1oojOfiazOlX1taVLuMVyeuJX5gCjPW7fU6moicR0UvuRZVtigjHm7K+480BeCR9xfSY9RCtuw/6nEyEQEVvfhQu1qXM6lvW17sUJt5m37mxjdS+M+ktRw9meZ1NJGgpqIXn4oIC6FnTDVmJMTSsWEF3kraSNyAJL5ZulOza0U8oqIXv7i8RCSv39uIL59oyeXFI+nz6VLufWcuq3Yd8jqaSNBR0YtfNbmqNF8/1Yp/3VmfjfuOcuvgWbw0bgUHj57yOppI0FDRi9+Fhhj3N7uSGf1jebhlFJ8u3E5sYhIfzd1CmhY7EfE7Fb3kmZJFwvnzrXWZ2KcNdSuW4OVvVtFx8CzmbfrZ62giAU1FL3muZvnijH70Ot5+8FqOnEjj/uHzePqTxez65bjX0UQCkopePGFmdKhfgR+ejaFP+xpMXf0T7QckM2T6j5w4fcbreCIBRUUvniocEUq/G2ryw7MxxNYqR+KU9dzwRjJTVu3R7ZgiPpJl0ZvZSDPba2Yrz9v2mpmtNbPlZjbOzEpdZHyomS0xs/G+Ci2Bp0qZIrz9UBNGP3odkWGhPP7RIh5+fyEb9v7qdTSRAi87Z/SjgPgLtk0F6jnnGgDrgRcvMr4PsCZH6STotKpelgl92vB/HeuwZNtB4gem8I/vV3PkhBY7EcmpLIveOZcCHLhg2xTn3G/z2ucBlTMaa2aVgVuAEbnMKUEkPDSE7q2rMiMhlrubVGbErM20S0zmi9TtnNViJyKXzBfX6LsDEzN5biDwHKCbpeWSlS1WiH/d1YCvn2xFlTKF+cPY5dz59hyWbf/F62giBUquit7MXgLSgNEZPNcR2OucW5TN13rczFLNLHXfvn25iSUBpmGVUnzZqyUD7mnIzl+O02nobJ4bu4x9R056HU2kQLDs3NlgZlHAeOdcvfO2dQN6Au2dc8cyGPMq0IVz/yOIBEoAXznnHsrq/aKjo11qamr2jkCCypETpxkyfQMjZ28mMiyUvjfUpGuLqwgP1Q1kEtzMbJFzLjqj53L0X4eZxXPuksxtGZU8gHPuRedcZedcFHA/MD07JS9yMcUjw3nx5muY1Lctja8qzSvjV9Nh0Exm/bjf62gi+VZ2bq8cA8wFapnZDjPrAQwBigNTzWypmQ1L37eimU3wa2IRoFq5YnzwSFNGdI3mVNpZHnpvPj0/SmX7gQzPO0SCWrYu3eQ1XbqRS3Hi9Bnem7WZIdM3cNY5esZU44mYahSOCPU6mkie8fmlG5H8JDI8lKfaVWd6Qgw31b2CN6f9SPsBSXy/fLdm14qgopcAUqFkYd58oDGf92xBySIRPPXJYjq/O591e454HU3EUyp6CTjNqpZhfO/WvHJ7PdbsOczNb87kL9+u4tAxza6V4KSil4AUGmJ0aX4VM/rH0rnZlXw4dwuxiTP4ZP42zmh2rQQZFb0EtNJFI3jl9np817s1NS4vzh/HraDT0Fks2nog68EiAUJFL0GhbsWSfNazOW8+0Jj9R05x19tz6ffZUn46fMLraCJ+p6KXoGFm3NawItMTYni6XXW+X76buMQkhiVv5GSaFjuRwKWil6BTJCKMhJtqMfXZtrSoVpZ/TVxL/MCZzFi71+toIn6hopegddVlRRnxcDSjHmmKAY+MWkj3UQvZsv+o19FEfEpFL0EvttblTOrblj/eXJsFmw9w4xsp/HvSWo6eTMt6sEgBoKIXASLCQni8bTWm94/h1oYVeTtpI3EDkvhm6U7NrpUCT0Uvcp7LS0Qy4N6GfPVkS8qXiKTPp0u5Z9hcVu485HU0kRxT0Ytk4NorS/P1k63491312bz/KLcOmcUfx63gwNFTXkcTuWQqepFMhIQY9zW9kukJsXRrGcVnC7cT+9oMPpizhbQzWh1TCg4VvUgWShYO58+31mVinzbUr1ySP3+7io6DZzF3489eRxPJFhW9SDbVLF+cj3tcx7CHruXIiTQeeHceT32ymF2/HPc6mshFqehFLoGZEV+vAtP6x9Dv+pr8sPon4gYkMXjaj5w4rdm1kj+p6EVyIDI8lD7X12Ba/xjial/OgKnrueGNZCav2qPbMSXfUdGL5ELl0kV468EmfPLodRQOD6XnR4voOnIBG/ZqsRPJP1T0Ij7QsnpZvn+mDX++tQ5Lt/9C/MCZ/H38ag6f0GIn4j0VvYiPhIeG8EirqiQlxHJPdGXem72ZuMRkvkjdzlktdiIeUtGL+NhlxQrx6p0N+Pap1lxZpjB/GLucO96ew9Ltv3gdTYKUil7ET+pXLsnYXi15/d6G7PrlOLcPnc0fvljGviMnvY4mQUZFL+JHISHGnddWZkZCLD1jrubrpTuJS0xixMxNnNbsWskjKnqRPFCsUBgvdriGyX3b0iSqNH//fg0dBs1k5o/7vI4mQUBFL5KHri5XjPe7NeW9h6M5feYsXd5bQM+PUtl+4JjX0SSAqehF8piZ0f6a8kzp15Y/3FSLlPX7af96Mq9PWcfxU5pdK76nohfxSKGwUJ5qV53pCTF0qHcFb07fQPsBSYxfvkuza8Wnsix6MxtpZnvNbOV5214zs7VmttzMxplZqQzGVTGzGWa22sxWmVkfX4cXCQQVShZm0P2N+bxnC0oVieDpT5bwwLvzWLvnsNfRJEBk54x+FBB/wbapQD3nXANgPfBiBuPSgP7OuTpAc+ApM6uTi6wiAa1Z1TJ817s1f7+9Hmv3HOHmQTP58zcr+eWYFjuR3Mmy6J1zKcCBC7ZNcc79tnLyPKByBuN2O+cWpz8+AqwBKuU6sUgACw0xHmp+FUkJsTzU/Co+mreVdolJfDJ/G2c0u1ZyyBfX6LsDEy+2g5lFAY2B+T54P5GAV6pIBH/rVI/xvdtQo3xx/jhuBbcNmUXqlgNZDxa5QK6K3sxe4twlmtEX2acY8CXQ1zmX6UVHM3vczFLNLHXfPt1bLAJQp2IJPnu8OYMfaMyBo6e4e9hc+n66hD2HTngdTQoQy86n++ln5OOdc/XO29YN6Am0d85leBOwmYUD44HJzrnXsxsqOjrapaamZnd3kaBw7FQabydt5J2UTYSFGL3jatC9dRSFwkK9jib5gJktcs5FZ/Rcjs7ozSweeA647SIlb8B7wJpLKXkRyViRiDD631iLH/rF0Kp6Wf49aS03vZHC9LU/eR1N8rns3F45BpgL1DKzHWbWAxgCFAemmtlSMxuWvm9FM5uQPrQV0AWIS99nqZnd7J/DEAkeV15WhHe7RvNB92aEhBjdR6XSfdRCNu8/6nU0yaeydekmr+nSjUj2nEo7ywdztjBo2o+cTDtDj9ZX83RcdYoVCvM6muQxn1+6EZH8ISIshMfaXs30hBg6NarEsOSNxCUmMW7JDs2ulf9S0YsEgMuLR5J4T0PGPdmSCiUj6ffZMu4eNpeVOw95HU3yARW9SABpfGVpxj3Ziv/c1YAt+49y65BZvPjVCg4c1ezaYKaiFwkwISHGvU2rMD0hlu6tqvJ56nZiX5vBB3O2kKbFToKSil4kQJUsHM7LHeswqU8b6lcuyZ+/XcUtb85izsb9XkeTPKaiFwlwNcoX5+Me1zHsoSYcPZVG53fn89Toxez85bjX0SSPqOhFgoCZEV/vCn54NoZnb6jJtLU/0X5AEm9O+5ETp7XYSaBT0YsEkcjwUJ5pX4Mfno2hfe3yvD51Pde/nsyklXt0O2YAU9GLBKHKpYsw9MFr+eSx6ygaEUavjxfRdeQCNuw94nU08QMVvUgQa1mtLN8/05q/3FqHZdt/IX7gTF4Zv5rDJ057HU18SEUvEuTCQkPo1qoqMxJiuSe6CiNnbyYuMYnPF27nrBY7CQgqehEB4LJihXj1zvp893RrrrqsKM99uZw73prNkm0HvY4muaSiF5HfqVepJGN7teCN+xqy+9AJ7nhrDglfLGPfkZNeR5McUtGLyP8wM+5oXJnpCbH0iqnGN0t3EpeYxIiZmziVptm1BY2KXkQyVaxQGC90qM3kvm1pElWav3+/hg6DUkhZr+U+CxIVvYhk6epyxRj1SDNGdovmzFlH15ELeOzDVLb9nOECc5LPqOhFJNviapdncr+2PB9fm9kb9nP9G8kMmLKOY6fSvI4mF6GiF5FLUigslCdiqzG9fyw317uCwdM3cP2AZMYv36XZtfmUil5EcuSKkpEMvL8xX/RqQakiETz9yRLuHz6PNbsPex1NLqCiF5FcaRpVhu96t+Yfd9Rj/U9HuOXNmfzfNyv55ZgWO8kvVPQikmuhIcaD113FjIRYujS/io/nbaVdYhKj52/ljGbXek5FLyI+U6pIBH/tVI/vn2lDzfLFeWncSm4dPIuFWw54HS2oqehFxOeuqVCCTx9vzpDOjTl47BT3DJtL30+XsOfQCa+jBSUVvYj4hZnRsUFFpvWPoXdcdSas3EPcgCTeStrAyTQtdpKXVPQi4ldFIsLof2MtfugXQ+vqZfnPpHXc+EYK09b85HW0oKGiF5E8ceVlRRjeNZoPuzcjLMTo8UEqj7y/gE37fvU6WsBT0YtInmpbsxyT+rblT7dcw8ItB7lpYAqvTlzDryc1u9ZfVPQikufCQ0N4tM3VTE+I4fZGlXgneRNxiUmMW7JDs2v9IMuiN7ORZrbXzFaet+01M1trZsvNbJyZlcpkbLyZrTOzDWb2gi+Di0jBd3nxSF67pyHjnmxJhZKR9PtsGXcPm8uKHYe8jhZQsnNGPwqIv2DbVKCec64BsB548cJBZhYKDAU6AHWAB8ysTq7SikhAanxlacY92Yr/3N2ArT8f5bahs3jxq+X8/KsWO/GFLIveOZcCHLhg2xTn3G8X1OYBlTMY2gzY4Jzb5Jw7BXwKdMplXhEJUCEhxr3RVZieEEuPVlX5InUH7RKTGDV7M2lntNhJbvjiGn13YGIG2ysB28/7eUf6tgyZ2eNmlmpmqfv2aVEDkWBVIjKcP3Wsw6S+bWhYpRR/+W41t7w5izkb93sdrcDKVdGb2UtAGjA6t0Gcc8Odc9HOuehy5crl9uVEpICrfnlxPuzejHe6NOHoqTQ6vzufp0YvZucvx72OVuCE5XSgmXUDOgLtXcYfk+8Eqpz3c+X0bSIi2WJm3FT3CmJqlmN4yibeStrAtLU/8URMdXrGXE1keKjXEQuEHJ3Rm1k88Bxwm3Mus7XEFgI1zKyqmUUA9wPf5iymiASzyPBQnmlfg2n9Y2l/TXne+GE97QckM2nlbt2OmQ3Zub1yDDAXqGVmO8ysBzAEKA5MNbOlZjYsfd+KZjYBIP3D2qeBycAa4HPn3Co/HYeIBIFKpQoztPO1jHmsOcUjw+j18WK6vLeAH3864nW0fM3y4/8No6OjXWpqqtcxRCQfSztzltHztzFgyjqOnjrDwy2i6HtDDUpEhnsdzRNmtsg5F53Rc5oZKyIFUlhoCA+3jCLpD+24r2kV3p+zmbjEJD5fuJ2zWuzkd1T0IlKglSkawT/vqM93T7cm6rKiPPflcm5/azaLtx30Olq+oaIXkYBQr1JJvujVgoH3NWLPoRPc+dYc+n++jL1HtNiJil5EAoaZcXvjSkxPiOWJ2Gp8u2wncYnJvJuyiVNpwTu7VkUvIgGnWKEwno+vzZR+MTSrWoZ/TFhD/KAUktcH56x7Fb2IBKyqZYsysltTRnaL5uxZx8MjF/DYh6ls+zmz6T+BSUUvIgEvrnZ5JvdrywsdajNnw36ufyOZxMnrOHYqOBY7UdGLSFAoFBZKr5hqTE+I5Zb6FRgyYwPtByTz7bJdAT+7VkUvIkGlfIlI3rivEWN7taBM0QieGbOE+4bPY/Wuw15H8xsVvYgEpeioMnz7dGv+eUd9fvzpCB0Hz+Tlr1fyy7FTXkfzORW9iASt0BCj83VXkpTQjq4tohg9fyuxiUl8PG8rZwJodq2KXkSCXski4fzltrpM6NOG2lcU509fr6Tj4Fks2Hwg68EFgIpeRCRd7StKMOax5gztfC2Hjp3i3nfm8syYJew5VLBn16roRUTOY2bc0qAC0/rH8kz7GkxatYe4AUkMnbGBk2lnvI6XIyp6EZEMFI4I5dkbajLt2Rja1CjLa5PXceMbKUxb81OBux1TRS8ichFVyhThnS7RfNSjGeGhIfT4IJVHRi1k475fvY6WbSp6EZFsaFOjHBP7tOHljnVYtOUg8QNTeHXCGo6cOO11tCyp6EVEsik8NIQerasyPSGWOxpX4p2UTcQNSOarxTvy9WInKnoRkUtUrngh/nN3Q75+qhUVSxXm2c+XcfewOazYccjraBlS0YuI5FCjKqUY90RLXru7AdsOHOO2obN48avl/PzrSa+j/Y6KXkQkF0JCjHuiqzA9IZZHW1fli9QdxCYm8f7szZw+kz8WO1HRi4j4QInIcF66pQ6T+ralUZVS/PW71dzy5kzmbNjvdTQVvYiIL1W/vBgfdm/G8C5NOH76DJ1HzOeJjxex46B3i52o6EVEfMzMuLHuFUztF0P/G2oyY91e2g9IZuAP6zlxOu9n16roRUT8JDI8lN7tazC9fyw31CnPwB9+pP2AZCat3J2ns2tV9CIiflaxVGGGdL6WTx9vTvHIMHp9vJiH3pvP+p+O5Mn7q+hFRPJI86svY3zv1vytU11W7jxMh0Ez+et3qzh03L+za1X0IiJ5KCw0hK4topiREMv9Taswas4W4hKT+GzhNr/Nrs2y6M1spJntNbOV5227x8xWmdlZM4u+yNh+6futNLMxZhbpq+AiIgVZmaIR/OOO+nz3dGuuLleU579cwe1vzeb4Kd9/WJudM/pRQPwF21YCdwIpmQ0ys0rAM0C0c64eEArcn7OYIiKBqV6lknzeswWD7m9Ek6tKUzgi1OfvEZbVDs65FDOLumDbGjh3C1E2Xr+wmZ0GigC7cpRSRCSAmRmdGlWiU6NKfnl9v12jd87tBBKBbcBu4JBzbkpm+5vZ42aWamap+/bt81csEZGg47eiN7PSQCegKlARKGpmD2W2v3NuuHMu2jkXXa5cOX/FEhEJOv686+Z6YLNzbp9z7jTwFdDSj+8nIiIZ8GfRbwOam1kRO3cxvz2wxo/vJyIiGcjO7ZVjgLlALTPbYWY9zOwOM9sBtAC+N7PJ6ftWNLMJAM65+cBYYDGwIv29hvvpOEREJBOWH1czj46OdqmpqV7HEBEpMMxskXMuw3lNmhkrIhLgVPQiIgFORS8iEuBU9CIiAS7Lr0AQEZEMOAdn0879deb0BY9Pw9kz5z1OgzNp5z2+cP/0x6HhUMJlXpwAAAUeSURBVO8un0dV0YuI/+SoDNML8Uz68/99nNnr/Lb/xcbm9HUyec3fxvla0XIqepGA5JwPCy2Dsdk+y8zGGeelvo4/yjArIeHnzoxDwiEkNJPHYRAadu7vIeEQFgEhRc4bG5rJ4/Qx/30c/vvX+d3jHIwNjfDLPxIVvRQM55dhrosotyXmizPO8x57WoYXls/FiigcwgtfvAwzfK3sFK6vxvr+K34DgYo+kGRYhn48U7zUX3cv+YzzgsLNa5mWz8WKKOz/l+H/FFFOCi0nZ4pZlLWFQNZfMS4BJPiK/r9lmMNC8+uZYk5eJz+VYXZ/3f2tDHP7q28WhZbV2IuVdUioylACRmAV/Ttt4eSvWZd1Xsu0fC6hDC/6K+vFzhSzKLTcjFUZihQIgVX05WqfK/NslaEfzxTPH6syFBGPBVbR36kvxxQRuZBmxoqIBDgVvYhIgFPRi4gEOBW9iEiAU9GLiAQ4Fb2ISIBT0YuIBDgVvYhIgDPnnNcZ/oeZ7QO25nB4WWC/D+MUBDrmwBdsxws65kt1lXOuXEZP5Muizw0zS3XORXudIy/pmANfsB0v6Jh9SZduREQCnIpeRCTABWLRB+M3m+mYA1+wHS/omH0m4K7Ri4jI7wXiGb2IiJxHRS8iEuAKZNGb2Ugz22tmKzN53szsTTPbYGbLzezavM7oa9k45gfTj3WFmc0xs4Z5ndHXsjrm8/ZramZpZnZ3XmXzl+wcs5nFmtlSM1tlZsl5mc/XsvHvdUkz+87MlqUf7yN5ndHXzKyKmc0ws9Xpx9Qng3182mEFsuiBUUD8RZ7vANRI/+tx4O08yORvo7j4MW8GYpxz9YFXCIwPskZx8WPGzEKBfwNT8iJQHhjFRY7ZzEoBbwG3OefqAvfkUS5/GcXF/4yfAlY75xoCscAAM4vIg1z+lAb0d87VAZoDT5lZnQv28WmHFciid86lAAcusksn4EN3zjyglJlVyJt0/pHVMTvn5jjnDqb/OA+onCfB/Cgbf84AvYEvgb3+T+R/2TjmzsBXzrlt6fsX6OPOxvE6oLiZGVAsfd+0vMjmL8653c65xemPjwBrgEoX7ObTDiuQRZ8NlYDt5/28g//9BxnIegATvQ7hb2ZWCbiDwPiNLbtqAqXNLMnMFplZV68D+dkQ4BpgF7AC6OOcO+ttJN8xsyigMTD/gqd82mGBtTi4YGbtOFf0rb3OkgcGAs87586eO+ELCmFAE6A9UBiYa2bznHPrvY3lNzcBS4E4oBow1cxmOucOexsr98ysGOd+G+3r7+MJ1KLfCVQ57+fK6dsCmpk1AEYAHZxzP3udJw9EA5+ml3xZ4GYzS3POfe1tLL/aAfzsnDsKHDWzFKAhEKhF/wjwL3duws8GM9sM1AYWeBsrd8wsnHMlP9o591UGu/i0wwL10s23QNf0T66bA4ecc7u9DuVPZnYl8BXQJYDP7n7HOVfVORflnIsCxgJPBnjJA3wDtDazMDMrAlzHuWu8gWob5357wczKA7WATZ4myqX0zxveA9Y4517PZDefdliBPKM3szGc+wS+rJntAP4MhAM454YBE4CbgQ3AMc6dFRRo2Tjm/wMuA95KP8NNK+jf/JeNYw44WR2zc26NmU0ClgNngRHOuYvefpqfZePP+BVglJmtAIxzl+oK+lcXtwK6ACvMbGn6tj8CV4J/OkxfgSAiEuAC9dKNiIikU9GLiAQ4Fb2ISIBT0YuIBDgVvYhIgFPRi4gEOBW9iEiA+39JYhpYGkSWSwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "a=9\n",
        "np.random.seed(a*9755)\n",
        "tf.random.set_seed(a*9755)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_val = X_train[int(0.85*X_train.shape[0]):int(X_train.shape[0])]\n",
        "y_val = y_train[int(0.85*y_train.shape[0]):int(y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train = X_train[0:int(0.85*X_train.shape[0])]\n",
        "y_train = y_train[0:int(0.85*y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "\n",
        "X_val=X_val.reshape(X_val.shape[0],X_val.shape[1]*X_val.shape[2])\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_val=X_val/255.0\n",
        "\n",
        "size_input = X_train.shape[1]\n",
        "size_input_layer = 64\n",
        "size_first_hidden = 32\n",
        "size_second_hidden = 16\n",
        "size_output = 10 #The digits go from 0 to 9 so in total we should have 10 classes\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "\n",
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input,size_input_layer, size_first_hidden, size_second_hidden, size_output, device):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_input_layer, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights for input\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_input_layer]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_input_layer]))\n",
        "     # Initialize weights between input layer and first hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_input_layer, self.size_first_hidden]))\n",
        "    # Initialize biases for first hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "     # Initialize weights between first hidden layer and second hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # Initialize biases for second hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # Initialize weights between second hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      regularizer=(tf.reduce_sum(tf.abs(self.W1)) + tf.reduce_sum(tf.abs(self.W2))\\\n",
        "                   + tf.reduce_sum(tf.abs(self.W3))+ tf.reduce_sum(tf.abs(self.W4)))/4.0  #L1 Regularization\n",
        "      current_loss = self.loss(predicted, y_train) + 0.08*regularizer\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    #Compute values in input layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)    \n",
        "    # Compute values in first hidden layer\n",
        "    what = tf.matmul(hhat, self.W2) + self.b2\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute values in second hidden layer\n",
        "    what = tf.matmul(hhat, self.W3) + self.b3\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W4) + self.b4\n",
        "    return tf.nn.softmax(output)\n",
        "\n",
        "  def compute_correct_preds(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "    correct = tf.Variable(0, dtype=tf.float32)\n",
        "    for i in range(y_pred_tf.shape[0]):\n",
        "      if tf.argmax(y_pred_tf[i]) == tf.argmax(y_true_tf[i]):\n",
        "        correct = correct + 1.0\n",
        "    return correct   \n",
        "\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device='none')\n",
        "\n",
        "time_start = time.time()\n",
        "valo_loss = 100.0\n",
        "val_loss  = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "train_loss = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(a*9755)).batch(20)\n",
        "  correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "\n",
        "  train_loss[0,epoch].assign(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Train Accuracy: {:.2f}%'.format((correct_preds/X_train.shape[0])*100.0))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(4)\n",
        "  valn_loss = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "  for inputs, outputs in val_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    valn_loss = valn_loss + mlp_on_cpu.loss(preds, outputs)\n",
        "  val_loss[0,epoch].assign(np.sum(valn_loss) / X_val.shape[0])\n",
        "  if val_loss[0,epoch] > valo_loss:\n",
        "    break\n",
        "  else:\n",
        "    valo_loss = val_loss[0,epoch]\n",
        "    W1 = mlp_on_cpu.variables[0]\n",
        "    W2 = mlp_on_cpu.variables[1]\n",
        "    W3 = mlp_on_cpu.variables[2]\n",
        "    W4 = mlp_on_cpu.variables[3]\n",
        "    b1 = mlp_on_cpu.variables[4]\n",
        "    b2 = mlp_on_cpu.variables[5]\n",
        "    b3 = mlp_on_cpu.variables[6]\n",
        "    b4 = mlp_on_cpu.variables[7]\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n",
        "\n",
        "train_loss = train_loss[train_loss>0.0]\n",
        "val_loss = val_loss[val_loss>0.0]\n",
        "e = e = tf.range(1, epoch+2, 1)\n",
        "plt.plot(e.numpy(),train_loss.numpy(),e.numpy(),val_loss.numpy())\n",
        "\n",
        "mlp_on_cpu.variables[0].assign(W1)\n",
        "mlp_on_cpu.variables[1].assign(W2)\n",
        "mlp_on_cpu.variables[2].assign(W3)\n",
        "mlp_on_cpu.variables[3].assign(W4)\n",
        "mlp_on_cpu.variables[4].assign(b1)\n",
        "mlp_on_cpu.variables[5].assign(b2)\n",
        "mlp_on_cpu.variables[6].assign(b3)\n",
        "mlp_on_cpu.variables[7].assign(b4)\n",
        "\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "print('Test Accuracy: {:.2f}%'.format((correct_preds/X_test.shape[0])*100.0))\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY AND L2 REGULARIZATION"
      ],
      "metadata": {
        "id": "vuSXm6tWyzqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1483c90f-0101-4a91-c31d-65c3d79506ba",
        "id": "k6T0r8IMv1ZD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 16.95%\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 13.347789215686275\n",
            "Train Accuracy: 27.15%\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 11.693960784313726\n",
            "Train Accuracy: 40.31%\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 9.295561274509804\n",
            "Train Accuracy: 21.89%\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 2.513093443627451\n",
            "Train Accuracy: 31.68%\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 1.8692444852941177\n",
            "Train Accuracy: 38.59%\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 1.6167633272058823\n",
            "Train Accuracy: 50.99%\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 1.3666387867647058\n",
            "Train Accuracy: 58.31%\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 1.1719021139705883\n",
            "Train Accuracy: 67.19%\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.9117474724264706\n",
            "Train Accuracy: 71.32%\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.781348268995098\n",
            "Train Accuracy: 74.29%\n",
            "Number of Epoch = 11 - Average Cross Entropy:= 0.7123932291666667\n",
            "Train Accuracy: 75.66%\n",
            "Number of Epoch = 12 - Average Cross Entropy:= 0.6773601409313725\n",
            "Train Accuracy: 76.44%\n",
            "Number of Epoch = 13 - Average Cross Entropy:= 0.6578444393382353\n",
            "Train Accuracy: 77.12%\n",
            "Number of Epoch = 14 - Average Cross Entropy:= 0.6432804074754902\n",
            "Train Accuracy: 77.65%\n",
            "Number of Epoch = 15 - Average Cross Entropy:= 0.6312188648897059\n",
            "Train Accuracy: 78.10%\n",
            "Number of Epoch = 16 - Average Cross Entropy:= 0.6203362055759803\n",
            "Train Accuracy: 78.56%\n",
            "Number of Epoch = 17 - Average Cross Entropy:= 0.6120675934436275\n",
            "Train Accuracy: 78.83%\n",
            "Number of Epoch = 18 - Average Cross Entropy:= 0.6060446920955882\n",
            "Train Accuracy: 79.12%\n",
            "Number of Epoch = 19 - Average Cross Entropy:= 0.6007819776348039\n",
            "Train Accuracy: 79.42%\n",
            "Number of Epoch = 20 - Average Cross Entropy:= 0.5958590303308824\n",
            "\n",
            "Total time taken (in seconds): 1606.66\n",
            "Test Accuracy: 78.85%\n",
            "Test MSE: 0.6166\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "a=9\n",
        "np.random.seed(a*9755)\n",
        "tf.random.set_seed(a*9755)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_val = X_train[int(0.85*X_train.shape[0]):int(X_train.shape[0])]\n",
        "y_val = y_train[int(0.85*y_train.shape[0]):int(y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train = X_train[0:int(0.85*X_train.shape[0])]\n",
        "y_train = y_train[0:int(0.85*y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "\n",
        "X_val=X_val.reshape(X_val.shape[0],X_val.shape[1]*X_val.shape[2])\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_val=X_val/255.0\n",
        "\n",
        "size_input = X_train.shape[1]\n",
        "size_input_layer = 64\n",
        "size_first_hidden = 32\n",
        "size_second_hidden = 16\n",
        "size_output = 10 #The digits go from 0 to 9 so in total we should have 10 classes\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "\n",
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input,size_input_layer, size_first_hidden, size_second_hidden, size_output, device):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_input_layer, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights for input\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_input_layer]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_input_layer]))\n",
        "     # Initialize weights between input layer and first hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_input_layer, self.size_first_hidden]))\n",
        "    # Initialize biases for first hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "     # Initialize weights between first hidden layer and second hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # Initialize biases for second hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # Initialize weights between second hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      regularizer=(tf.reduce_sum(tf.square(self.W1)) + tf.reduce_sum(tf.square(self.W2))\\\n",
        "                   + tf.reduce_sum(tf.square(self.W3))+ tf.reduce_sum(tf.square(self.W4)))/4.0  #L2 Regularization\n",
        "      current_loss = self.loss(predicted, y_train) + 0.05*regularizer\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    #Compute values in input layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)    \n",
        "    # Compute values in first hidden layer\n",
        "    what = tf.matmul(hhat, self.W2) + self.b2\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute values in second hidden layer\n",
        "    what = tf.matmul(hhat, self.W3) + self.b3\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W4) + self.b4\n",
        "    return tf.nn.softmax(output)\n",
        "\n",
        "  def compute_correct_preds(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "    correct = tf.Variable(0, dtype=tf.float32)\n",
        "    for i in range(y_pred_tf.shape[0]):\n",
        "      if tf.argmax(y_pred_tf[i]) == tf.argmax(y_true_tf[i]):\n",
        "        correct = correct + 1.0\n",
        "    return correct   \n",
        "\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device='none')\n",
        "\n",
        "time_start = time.time()\n",
        "valo_loss = 100.0\n",
        "val_loss  = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "train_loss = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(a*9755)).batch(20)\n",
        "  correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "\n",
        "  train_loss[0,epoch].assign(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Train Accuracy: {:.2f}%'.format((correct_preds/X_train.shape[0])*100.0))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(4)\n",
        "  valn_loss = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "  for inputs, outputs in val_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    valn_loss = valn_loss + mlp_on_cpu.loss(preds, outputs)\n",
        "  val_loss[0,epoch].assign(np.sum(valn_loss) / X_val.shape[0])\n",
        "  if val_loss[0,epoch] > valo_loss:\n",
        "    break\n",
        "  else:\n",
        "    valo_loss = val_loss[0,epoch]\n",
        "    W1 = mlp_on_cpu.variables[0]\n",
        "    W2 = mlp_on_cpu.variables[1]\n",
        "    W3 = mlp_on_cpu.variables[2]\n",
        "    W4 = mlp_on_cpu.variables[3]\n",
        "    b1 = mlp_on_cpu.variables[4]\n",
        "    b2 = mlp_on_cpu.variables[5]\n",
        "    b3 = mlp_on_cpu.variables[6]\n",
        "    b4 = mlp_on_cpu.variables[7]\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n",
        "\n",
        "train_loss = train_loss[train_loss>0.0]\n",
        "val_loss = val_loss[val_loss>0.0]\n",
        "e = e = tf.range(1, epoch+2, 1)\n",
        "plt.plot(e.numpy(),train_loss.numpy(),e.numpy(),val_loss.numpy())\n",
        "\n",
        "mlp_on_cpu.variables[0].assign(W1)\n",
        "mlp_on_cpu.variables[1].assign(W2)\n",
        "mlp_on_cpu.variables[2].assign(W3)\n",
        "mlp_on_cpu.variables[3].assign(W4)\n",
        "mlp_on_cpu.variables[4].assign(b1)\n",
        "mlp_on_cpu.variables[5].assign(b2)\n",
        "mlp_on_cpu.variables[6].assign(b3)\n",
        "mlp_on_cpu.variables[7].assign(b4)\n",
        "\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "print('Test Accuracy: {:.2f}%'.format((correct_preds/X_test.shape[0])*100.0))\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))"
      ]
    }
  ]
}