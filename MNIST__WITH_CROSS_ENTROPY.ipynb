{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST _WITH_CROSS_ENTROPY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY"
      ],
      "metadata": {
        "id": "jPHcUkZt4grA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "Mn3WwrVvbZEV",
        "outputId": "5d518b80-2999-43f2-fd8c-329d852c50b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-404fb12eb0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mmlp_on_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mcorrect_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_preds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmlp_on_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_correct_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-404fb12eb0b3>\u001b[0m in \u001b[0;36mcompute_correct_preds\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_tf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_tf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1029\u001b[0m                                                   stack(strides))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "a=9\n",
        "np.random.seed(a*9755)\n",
        "tf.random.set_seed(a*9755)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "X_val = X_train[int(0.85*X_train.shape[0]):int(X_train.shape[0])]\n",
        "y_val = y_train[int(0.85*y_train.shape[0]):int(y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train = X_train[0:int(0.85*X_train.shape[0])]\n",
        "y_train = y_train[0:int(0.85*y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "\n",
        "X_val=X_val.reshape(X_val.shape[0],X_val.shape[1]*X_val.shape[2])\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_val=X_val/255.0\n",
        "\n",
        "size_input = X_train.shape[1]\n",
        "size_input_layer = 64\n",
        "size_first_hidden = 32\n",
        "size_second_hidden = 16\n",
        "size_output = 10 #The digits go from 0 to 9 so in total we should have 10 classes\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "\n",
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input,size_input_layer, size_first_hidden, size_second_hidden, size_output, device):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_input_layer, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights for input\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_input_layer]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_input_layer]))\n",
        "     # Initialize weights between input layer and first hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_input_layer, self.size_first_hidden]))\n",
        "    # Initialize biases for first hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "     # Initialize weights between first hidden layer and second hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # Initialize biases for second hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # Initialize weights between second hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    #Compute values in input layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)    \n",
        "    # Compute values in first hidden layer\n",
        "    what = tf.matmul(hhat, self.W2) + self.b2\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute values in second hidden layer\n",
        "    what = tf.matmul(hhat, self.W3) + self.b3\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W4) + self.b4\n",
        "    return tf.nn.softmax(output)\n",
        "\n",
        "  def compute_correct_preds(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "    correct = tf.Variable(0, dtype=tf.float32)\n",
        "    for i in range(y_pred_tf.shape[0]):\n",
        "      if tf.argmax(y_pred_tf[i]) == tf.argmax(y_true_tf[i]):\n",
        "        correct = correct + 1.0\n",
        "    return correct   \n",
        "\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device='none')\n",
        "\n",
        "time_start = time.time()\n",
        "valo_loss = 100.0\n",
        "val_loss  = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "train_loss = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*a*(9755)).batch(20)\n",
        "  correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "\n",
        "  train_loss[0,epoch].assign(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Train Accuracy: {:.2f}%'.format((correct_preds/X_train.shape[0])*100.0))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(4)\n",
        "  valn_loss = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "  for inputs, outputs in val_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    valn_loss = valn_loss + mlp_on_cpu.loss(preds, outputs)\n",
        "  val_loss[0,epoch].assign(np.sum(valn_loss) / X_val.shape[0])\n",
        "  if val_loss[0,epoch] > valo_loss:\n",
        "    break\n",
        "  else:\n",
        "    valo_loss = val_loss[0,epoch]\n",
        "    W1 = mlp_on_cpu.variables[0]\n",
        "    W2 = mlp_on_cpu.variables[1]\n",
        "    W3 = mlp_on_cpu.variables[2]\n",
        "    W4 = mlp_on_cpu.variables[3]\n",
        "    b1 = mlp_on_cpu.variables[4]\n",
        "    b2 = mlp_on_cpu.variables[5]\n",
        "    b3 = mlp_on_cpu.variables[6]\n",
        "    b4 = mlp_on_cpu.variables[7]\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n",
        "\n",
        "train_loss = train_loss[train_loss>0.0]\n",
        "val_loss = val_loss[val_loss>0.0]\n",
        "e = e = tf.range(1, epoch+2, 1)\n",
        "plt.plot(e.numpy(),train_loss.numpy(),e.numpy(),val_loss.numpy())\n",
        "\n",
        "mlp_on_cpu.variables[0].assign(W1)\n",
        "mlp_on_cpu.variables[1].assign(W2)\n",
        "mlp_on_cpu.variables[2].assign(W3)\n",
        "mlp_on_cpu.variables[3].assign(W4)\n",
        "mlp_on_cpu.variables[4].assign(b1)\n",
        "mlp_on_cpu.variables[5].assign(b2)\n",
        "mlp_on_cpu.variables[6].assign(b3)\n",
        "mlp_on_cpu.variables[7].assign(b4)\n",
        "\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "print('Test Accuracy: {:.2f}%'.format((correct_preds/X_test.shape[0])*100.0))\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY AND L1 REGULARIZATION\n",
        "\n"
      ],
      "metadata": {
        "id": "x_oK8eCsvsEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a74045b-e8c2-4362-f5bb-7382cf9464c2",
        "id": "Y5Rn7KzcwdIK"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 17.17%\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 13.316332107843138\n",
            "Train Accuracy: 23.00%\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 12.382773284313725\n",
            "Train Accuracy: 25.26%\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 11.984634803921569\n",
            "Train Accuracy: 29.22%\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 11.22552818627451\n",
            "Train Accuracy: 34.79%\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 10.037400735294117\n",
            "Train Accuracy: 19.30%\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 2.992622549019608\n",
            "Train Accuracy: 18.24%\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 2.307390931372549\n",
            "Train Accuracy: 22.10%\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 2.1689813112745098\n",
            "Train Accuracy: 31.77%\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 1.9171660539215687\n",
            "Train Accuracy: 37.90%\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 1.7517306985294117\n",
            "Train Accuracy: 43.87%\n",
            "Number of Epoch = 11 - Average Cross Entropy:= 1.6373641237745098\n",
            "Train Accuracy: 51.09%\n",
            "Number of Epoch = 12 - Average Cross Entropy:= 1.5082625612745097\n",
            "Train Accuracy: 56.61%\n",
            "Number of Epoch = 13 - Average Cross Entropy:= 1.3474263174019607\n",
            "Train Accuracy: 60.61%\n",
            "Number of Epoch = 14 - Average Cross Entropy:= 1.219986213235294\n",
            "Train Accuracy: 63.46%\n",
            "Number of Epoch = 15 - Average Cross Entropy:= 1.1348525582107842\n",
            "Train Accuracy: 65.49%\n",
            "Number of Epoch = 16 - Average Cross Entropy:= 1.0681999846813726\n",
            "Train Accuracy: 67.38%\n",
            "Number of Epoch = 17 - Average Cross Entropy:= 1.0246443780637255\n",
            "Train Accuracy: 68.53%\n",
            "Number of Epoch = 18 - Average Cross Entropy:= 1.0034195772058823\n",
            "Train Accuracy: 69.34%\n",
            "Number of Epoch = 19 - Average Cross Entropy:= 0.9921937806372549\n",
            "Train Accuracy: 69.87%\n",
            "Number of Epoch = 20 - Average Cross Entropy:= 0.9813983609068627\n",
            "\n",
            "Total time taken (in seconds): 1487.96\n",
            "Test Accuracy: 71.33%\n",
            "Test MSE: 0.9505\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "a=9\n",
        "np.random.seed(a*9755)\n",
        "tf.random.set_seed(a*9755)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "X_val = X_train[int(0.85*X_train.shape[0]):int(X_train.shape[0])]\n",
        "y_val = y_train[int(0.85*y_train.shape[0]):int(y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train = X_train[0:int(0.85*X_train.shape[0])]\n",
        "y_train = y_train[0:int(0.85*y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "\n",
        "X_val=X_val.reshape(X_val.shape[0],X_val.shape[1]*X_val.shape[2])\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_val=X_val/255.0\n",
        "\n",
        "size_input = X_train.shape[1]\n",
        "size_input_layer = 64\n",
        "size_first_hidden = 32\n",
        "size_second_hidden = 16\n",
        "size_output = 10 #The digits go from 0 to 9 so in total we should have 10 classes\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "\n",
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input,size_input_layer, size_first_hidden, size_second_hidden, size_output, device):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_input_layer, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights for input\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_input_layer]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_input_layer]))\n",
        "     # Initialize weights between input layer and first hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_input_layer, self.size_first_hidden]))\n",
        "    # Initialize biases for first hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "     # Initialize weights between first hidden layer and second hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # Initialize biases for second hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # Initialize weights between second hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      regularizer=(tf.reduce_sum(tf.abs(self.W1)) + tf.reduce_sum(tf.abs(self.W2))\\\n",
        "                   + tf.reduce_sum(tf.abs(self.W3))+ tf.reduce_sum(tf.abs(self.W4)))/4.0  #L1 Regularization\n",
        "      current_loss = self.loss(predicted, y_train) + 0.08*regularizer\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    #Compute values in input layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)    \n",
        "    # Compute values in first hidden layer\n",
        "    what = tf.matmul(hhat, self.W2) + self.b2\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute values in second hidden layer\n",
        "    what = tf.matmul(hhat, self.W3) + self.b3\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W4) + self.b4\n",
        "    return tf.nn.softmax(output)\n",
        "\n",
        "  def compute_correct_preds(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "    correct = tf.Variable(0, dtype=tf.float32)\n",
        "    for i in range(y_pred_tf.shape[0]):\n",
        "      if tf.argmax(y_pred_tf[i]) == tf.argmax(y_true_tf[i]):\n",
        "        correct = correct + 1.0\n",
        "    return correct   \n",
        "\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device='none')\n",
        "\n",
        "time_start = time.time()\n",
        "valo_loss = 100.0\n",
        "val_loss  = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "train_loss = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(a*9755)).batch(20)\n",
        "  correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "\n",
        "  train_loss[0,epoch].assign(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Train Accuracy: {:.2f}%'.format((correct_preds/X_train.shape[0])*100.0))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(4)\n",
        "  valn_loss = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "  for inputs, outputs in val_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    valn_loss = valn_loss + mlp_on_cpu.loss(preds, outputs)\n",
        "  val_loss[0,epoch].assign(np.sum(valn_loss) / X_val.shape[0])\n",
        "  if val_loss[0,epoch] > valo_loss:\n",
        "    break\n",
        "  else:\n",
        "    valo_loss = val_loss[0,epoch]\n",
        "    W1 = mlp_on_cpu.variables[0]\n",
        "    W2 = mlp_on_cpu.variables[1]\n",
        "    W3 = mlp_on_cpu.variables[2]\n",
        "    W4 = mlp_on_cpu.variables[3]\n",
        "    b1 = mlp_on_cpu.variables[4]\n",
        "    b2 = mlp_on_cpu.variables[5]\n",
        "    b3 = mlp_on_cpu.variables[6]\n",
        "    b4 = mlp_on_cpu.variables[7]\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n",
        "\n",
        "train_loss = train_loss[train_loss>0.0]\n",
        "val_loss = val_loss[val_loss>0.0]\n",
        "e = e = tf.range(1, epoch+2, 1)\n",
        "plt.plot(e.numpy(),train_loss.numpy(),e.numpy(),val_loss.numpy())\n",
        "\n",
        "mlp_on_cpu.variables[0].assign(W1)\n",
        "mlp_on_cpu.variables[1].assign(W2)\n",
        "mlp_on_cpu.variables[2].assign(W3)\n",
        "mlp_on_cpu.variables[3].assign(W4)\n",
        "mlp_on_cpu.variables[4].assign(b1)\n",
        "mlp_on_cpu.variables[5].assign(b2)\n",
        "mlp_on_cpu.variables[6].assign(b3)\n",
        "mlp_on_cpu.variables[7].assign(b4)\n",
        "\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "print('Test Accuracy: {:.2f}%'.format((correct_preds/X_test.shape[0])*100.0))\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY AND L2 REGULARIZATION"
      ],
      "metadata": {
        "id": "A2ubLP3QwFMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e13ad7c1-75af-404a-8bd0-d34aa97b1cd8",
        "id": "k6T0r8IMv1ZD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 17.95%\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 13.151252450980392\n",
            "Train Accuracy: 27.21%\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 11.614685049019608\n",
            "Train Accuracy: 30.57%\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 11.015616421568627\n",
            "Train Accuracy: 18.84%\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 4.702105698529412\n",
            "Train Accuracy: 14.53%\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 2.3027530637254903\n",
            "Train Accuracy: 20.69%\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 2.1234742647058824\n",
            "Train Accuracy: 27.40%\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 1.9476372549019607\n",
            "Train Accuracy: 37.13%\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 1.747192861519608\n",
            "Train Accuracy: 51.09%\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 1.4613841911764707\n",
            "Train Accuracy: 64.63%\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 1.0751798406862745\n",
            "Train Accuracy: 74.02%\n",
            "Number of Epoch = 11 - Average Cross Entropy:= 0.8141550245098039\n",
            "Train Accuracy: 78.58%\n",
            "Number of Epoch = 12 - Average Cross Entropy:= 0.6960822610294117\n",
            "Train Accuracy: 81.04%\n",
            "Number of Epoch = 13 - Average Cross Entropy:= 0.6359049479166666\n",
            "Train Accuracy: 82.57%\n",
            "Number of Epoch = 14 - Average Cross Entropy:= 0.5966632965686275\n",
            "Train Accuracy: 83.83%\n",
            "Number of Epoch = 15 - Average Cross Entropy:= 0.5685835248161765\n",
            "Train Accuracy: 84.70%\n",
            "Number of Epoch = 16 - Average Cross Entropy:= 0.5467948069852941\n",
            "Train Accuracy: 85.35%\n",
            "Number of Epoch = 17 - Average Cross Entropy:= 0.5288223422181373\n",
            "Train Accuracy: 86.00%\n",
            "Number of Epoch = 18 - Average Cross Entropy:= 0.5128275888480393\n",
            "Train Accuracy: 86.61%\n",
            "Number of Epoch = 19 - Average Cross Entropy:= 0.4982068780637255\n",
            "Train Accuracy: 87.05%\n",
            "Number of Epoch = 20 - Average Cross Entropy:= 0.4852652420343137\n",
            "\n",
            "Total time taken (in seconds): 1624.93\n",
            "Test Accuracy: 87.09%\n",
            "Test MSE: 0.4707\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "a=9\n",
        "np.random.seed(a*9755)\n",
        "tf.random.set_seed(a*9755)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "X_val = X_train[int(0.85*X_train.shape[0]):int(X_train.shape[0])]\n",
        "y_val = y_train[int(0.85*y_train.shape[0]):int(y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train = X_train[0:int(0.85*X_train.shape[0])]\n",
        "y_train = y_train[0:int(0.85*y_train.shape[0])]\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "\n",
        "X_val=X_val.reshape(X_val.shape[0],X_val.shape[1]*X_val.shape[2])\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_val=X_val/255.0\n",
        "\n",
        "size_input = X_train.shape[1]\n",
        "size_input_layer = 64\n",
        "size_first_hidden = 32\n",
        "size_second_hidden = 16\n",
        "size_output = 10 #The digits go from 0 to 9 so in total we should have 10 classes\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "\n",
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input,size_input_layer, size_first_hidden, size_second_hidden, size_output, device):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_input_layer, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights for input\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_input_layer]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_input_layer]))\n",
        "     # Initialize weights between input layer and first hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_input_layer, self.size_first_hidden]))\n",
        "    # Initialize biases for first hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "     # Initialize weights between first hidden layer and second hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # Initialize biases for second hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # Initialize weights between second hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      regularizer=(tf.reduce_sum(tf.square(self.W1)) + tf.reduce_sum(tf.square(self.W2))\\\n",
        "                   + tf.reduce_sum(tf.square(self.W3))+ tf.reduce_sum(tf.square(self.W4)))/4.0  #L2 Regularization\n",
        "      current_loss = self.loss(predicted, y_train) + 0.05*regularizer\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    #Compute values in input layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)    \n",
        "    # Compute values in first hidden layer\n",
        "    what = tf.matmul(hhat, self.W2) + self.b2\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute values in second hidden layer\n",
        "    what = tf.matmul(hhat, self.W3) + self.b3\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W4) + self.b4\n",
        "    return tf.nn.softmax(output)\n",
        "\n",
        "  def compute_correct_preds(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "    correct = tf.Variable(0, dtype=tf.float32)\n",
        "    for i in range(y_pred_tf.shape[0]):\n",
        "      if tf.argmax(y_pred_tf[i]) == tf.argmax(y_true_tf[i]):\n",
        "        correct = correct + 1.0\n",
        "    return correct   \n",
        "\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_input_layer, size_first_hidden, size_second_hidden, size_output, device='none')\n",
        "\n",
        "time_start = time.time()\n",
        "valo_loss = 100.0\n",
        "val_loss  = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "train_loss = tf.Variable(tf.zeros([1, NUM_EPOCHS]),dtype=tf.float32)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(a*9755)).batch(20)\n",
        "  correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "\n",
        "  train_loss[0,epoch].assign(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Train Accuracy: {:.2f}%'.format((correct_preds/X_train.shape[0])*100.0))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(4)\n",
        "  valn_loss = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "  for inputs, outputs in val_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    valn_loss = valn_loss + mlp_on_cpu.loss(preds, outputs)\n",
        "  val_loss[0,epoch].assign(np.sum(valn_loss) / X_val.shape[0])\n",
        "  if val_loss[0,epoch] > valo_loss:\n",
        "    break\n",
        "  else:\n",
        "    valo_loss = val_loss[0,epoch]\n",
        "    W1 = mlp_on_cpu.variables[0]\n",
        "    W2 = mlp_on_cpu.variables[1]\n",
        "    W3 = mlp_on_cpu.variables[2]\n",
        "    W4 = mlp_on_cpu.variables[3]\n",
        "    b1 = mlp_on_cpu.variables[4]\n",
        "    b2 = mlp_on_cpu.variables[5]\n",
        "    b3 = mlp_on_cpu.variables[6]\n",
        "    b4 = mlp_on_cpu.variables[7]\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n",
        "\n",
        "train_loss = train_loss[train_loss>0.0]\n",
        "val_loss = val_loss[val_loss>0.0]\n",
        "e = e = tf.range(1, epoch+2, 1)\n",
        "plt.plot(e.numpy(),train_loss.numpy(),e.numpy(),val_loss.numpy())\n",
        "\n",
        "mlp_on_cpu.variables[0].assign(W1)\n",
        "mlp_on_cpu.variables[1].assign(W2)\n",
        "mlp_on_cpu.variables[2].assign(W3)\n",
        "mlp_on_cpu.variables[3].assign(W4)\n",
        "mlp_on_cpu.variables[4].assign(b1)\n",
        "mlp_on_cpu.variables[5].assign(b2)\n",
        "mlp_on_cpu.variables[6].assign(b3)\n",
        "mlp_on_cpu.variables[7].assign(b4)\n",
        "\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_preds = tf.Variable(0, dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  correct_preds = correct_preds + mlp_on_cpu.compute_correct_preds(preds, outputs)\n",
        "print('Test Accuracy: {:.2f}%'.format((correct_preds/X_test.shape[0])*100.0))\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))"
      ]
    }
  ]
}